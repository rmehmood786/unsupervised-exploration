# Unsupervised Learning: From Lab Notebook to Research-Style Project

This repository elevates the original Jupyter notebook **“Lab 8 – Unsupervised learning.ipynb”** into a clean, reproducible, and extensible project suitable for ML/AI research internship applications.

## What’s inside
- **Modular library (`src/unsup/`)** for embeddings (PCA, t‑SNE, UMAP), clustering (KMeans, DBSCAN, Agglomerative, GMM), evaluation, and visualization.
- **Reproducible scripts** for running experiments and saving metrics/figures.
- **Unit tests** to show engineering discipline.
- **Makefile** with common tasks; `pyproject.toml` for packaging; **MIT license**.
- **Original notebook** is preserved in `notebooks/` for interactive exploration.

> Detected in your notebook: **Algorithms** → PCA. **Datasets** → MNIST.
  (The codebase supports more methods out of the box.)

## Quickstart
```bash
python -m venv .venv && source .venv/bin/activate  # or .venv\Scripts\activate on Windows
make install
make run  # runs Iris with PCA+KMeans and saves outputs/ and metrics
```

Or run a custom experiment:
```bash
python scripts/run_experiment.py --dataset wine --embed umap --cluster gmm --n-clusters 3 --outdir outputs/wine_umap_gmm
```

## Results & Reproducibility
Running `make run` produces:
- a 2D scatter plot of the embedded data colored by cluster labels (under `outputs/`), and
- a `metrics.json` with internal and external clustering scores (silhouette, Calinski–Harabasz, Davies–Bouldin; ARI, NMI, homogeneity/completeness/V-measure when ground truth is available).

## Structure
```
.
├── src/unsup/               # reusable library
├── scripts/                 # CLI entry points
├── tests/                   # unit tests (pytest)
├── notebooks/               # original and derived analyses
├── experiments/configs/     # (add YAML configs if you want grid runs)
├── docs/                    # figures and reports
└── outputs/                 # generated by scripts
```

## How to extend (talking points for interviews)
- **Modeling**: add spectral clustering, HDBSCAN, or deep embeddings (e.g., autoencoders).
- **Evaluation**: include stability (bootstrap) and robustness to noise; clusterability metrics (e.g., Hopkins statistic).
- **Experimentation**: manage sweeps via YAML in `experiments/configs/` and a loop in `scripts/run_experiment.py`.
- **Reporting**: create a polished notebook in `notebooks/` that imports `unsup` and regenerates figures for a paper-style report.
- **Software craft**: add CI (GitHub Actions), pre-commit hooks, and docstrings with `pdoc` or `sphinx`.

## Credits
Original work adapted from the provided notebook. This repo generalizes it into a research-friendly, reproducible codebase.
